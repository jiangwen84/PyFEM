{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "362628c7-ed0c-408a-a16d-945b2b6fea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import torch\n",
    "from model import MixtureOfExperts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ee6fc3-875f-4280-81d1-8ad43c87b392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MixtureOfExperts(\n",
       "  (gate): SoftmaxGate(\n",
       "    (linear_gate): LinearHN(\n",
       "      (hn): MLP(\n",
       "        (sequential): Sequential(\n",
       "          (0): Linear(in_features=6, out_features=128, bias=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): SiLU()\n",
       "          (3): Dropout(p=0.5, inplace=False)\n",
       "          (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (6): SiLU()\n",
       "          (7): Dropout(p=0.5, inplace=False)\n",
       "          (8): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (9): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (10): SiLU()\n",
       "          (11): Dropout(p=0.5, inplace=False)\n",
       "          (12): Linear(in_features=128, out_features=448, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (linear): Linear(in_features=6, out_features=64, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (experts): ModuleList(\n",
       "    (0-63): 64 x LinearHN(\n",
       "      (hn): MLP(\n",
       "        (sequential): Sequential(\n",
       "          (0): Linear(in_features=6, out_features=32, bias=True)\n",
       "          (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): SiLU()\n",
       "          (3): Dropout(p=0.5, inplace=False)\n",
       "          (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (5): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (6): SiLU()\n",
       "          (7): Dropout(p=0.5, inplace=False)\n",
       "          (8): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (9): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (10): SiLU()\n",
       "          (11): Dropout(p=0.5, inplace=False)\n",
       "          (12): Linear(in_features=32, out_features=21, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (linear): Linear(in_features=6, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading pytorch model\n",
    "\n",
    "model_name = f\"model_experiment_5_1101443/checkpoint_savetime_1101443_batchsize_16384_numexperts_64.pt\"\n",
    "device = 'cpu'\n",
    "num_experts = int( model_name.split('_')[-1][:-3] )\n",
    "print(num_experts)\n",
    "num_vars = 6\n",
    "gate_features = 128\n",
    "expert_features = 32\n",
    "out_features = 3\n",
    "model = MixtureOfExperts(num_vars, gate_features, expert_features, out_features, num_experts)\n",
    "model.load_state_dict(torch.load(model_name, map_location=torch.device(device)))\n",
    "model.to(torch.double)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ec6d485-3ab8-4c69-ab38-0ff85d9b8fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## loading dataset \n",
    "# #This step requires the HT9 dataset. To remove this dependence, we will pickle only the necessery information.\n",
    "\n",
    "# from loaders import filtered_train_test_dataset, load_simulations, load_data\n",
    "\n",
    "# input_names = ['vmJ2', 'temperature', 'evm', 'rhoc', 'rhow', 'flux']\n",
    "# output_names = ['evm', 'rhoc', 'rhow']\n",
    "\n",
    "# # LOADING THE DATASET AND DATA TRANSFORMS\n",
    "# train_dataset, test_dataset = filtered_train_test_dataset()\n",
    "# data_transform = train_dataset.data_transform\n",
    "# xtr_full, ytr_full = load_data('train')\n",
    "\n",
    "# simdata = load_simulations(mode='valid')\n",
    "\n",
    "# # pickling some run specific information -- needed for the model\n",
    "\n",
    "# sim_id = 0\n",
    "# init_data = {'vmJ2' : simdata['sim'][sim_id]['xinit'][0],\n",
    "#              'temperature' :simdata['sim'][sim_id]['xinit'][1],\n",
    "#              'evm' : simdata['sim'][sim_id]['xinit'][2],\n",
    "#              'rhoc' : simdata['sim'][sim_id]['xinit'][3],\n",
    "#              'rhow' : simdata['sim'][sim_id]['xinit'][4],\n",
    "#              'flux' : simdata['sim'][sim_id]['xinit'][5],\n",
    "#              }\n",
    "\n",
    "# with open(f\"init_data.pickle\",\"wb\") as fhandle:\n",
    "#     pickle.dump(init_data, fhandle)\n",
    "\n",
    "# # pickling the data transform\n",
    "\n",
    "# with open(f\"transform.pickle\",\"wb\") as fhandle:\n",
    "#     pickle.dump(data_transform, fhandle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cebbae6-a79a-4a7b-89e1-73523ad0f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"transform.pickle\",\"rb\") as fhandle:\n",
    "    data_transform = pickle.load(fhandle)\n",
    "\n",
    "with open(f\"init_data.pickle\",\"rb\") as fhandle:\n",
    "    init_data = pickle.load(fhandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "704a4b81-a8b6-4824-939a-9765dc2ef1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## surrogate eval and jacobian wrapper, for pointwise evaluations\n",
    "\n",
    "class ModelWrapper:\n",
    "\n",
    "    def __init__(self, model, data_transform, init_data):\n",
    "        self.data_transform = data_transform\n",
    "        self.model = model\n",
    "        self.init_data = init_data\n",
    "        \n",
    "        self.ninputs = self.data_transform['input'].length\n",
    "        self.noutputs = self.data_transform['output'].length\n",
    "\n",
    "    def eval(self, x: np.array):\n",
    "        # x is (n,)\n",
    "        x_extended = np.array([[self.init_data['vmJ2'], \n",
    "                       self.init_data['temperature'],\n",
    "                       x[0], x[1], x[2],\n",
    "                       self.init_data['flux']]])\n",
    "        z = torch.tensor(self.data_transform['input'].transform(x_extended), dtype=torch.double)         \n",
    "        # eval surrogates              \n",
    "        with torch.no_grad():\n",
    "            outs  = self.model(z)\n",
    "        return self.data_transform['output'].inverse_transform(outs.numpy()).reshape((-1,))\n",
    "\n",
    "    def eval_jacobian(self, x: np.array):\n",
    "        '''\n",
    "        pytorch jacobian modified from\n",
    "        https://gist.github.com/sbarratt/37356c46ad1350d4c30aefbd488a4faa\n",
    "        '''\n",
    "        # x is (n,)\n",
    "\n",
    "        x_extended = np.array([[self.init_data['vmJ2'], \n",
    "                       self.init_data['temperature'],\n",
    "                       x[0], x[1], x[2],\n",
    "                       self.init_data['flux']]])\n",
    "        Jin = self.data_transform['input'].forward_derivative(x_extended)\n",
    "        z = torch.tensor( self.data_transform['input'].transform(x_extended), dtype=torch.double).squeeze()\n",
    "        z = z.repeat(self.noutputs, 1)\n",
    "        z.requires_grad_(True)\n",
    "        y = self.model(z)\n",
    "        y.backward(torch.eye(self.noutputs))\n",
    "        Jmod = z.grad.data.numpy()\n",
    "        Jout = data_transform['output'].inverse_derivative( y[0].detach().numpy()[None,:] )\n",
    "        J = Jout[:,None]*(Jmod * Jin) # (3,6) jacobian for all 6 inputs\n",
    "        return J[:,2:5] # (3,3) jacobian for just the state variables \n",
    "\n",
    "    def eval_func_wrapper(self, t, x):\n",
    "        '''\n",
    "        wrapper for scipy.integrate.solve_ivp\n",
    "        '''\n",
    "        return self.eval(x)\n",
    "\n",
    "    def eval_jacobian_wrapper(self, t, x):\n",
    "        '''\n",
    "        wrapper for scipy.integrate.solve_ivp\n",
    "        '''\n",
    "        return self.eval_jacobian(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f32f75c8-68a3-444b-8cbf-8630ec571fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing finite difference to formulated Jacobian\n",
    "# from scipy.optimize import check_grad\n",
    "\n",
    "# sim_id = 0\n",
    "# init_data = {'vmJ2' : simdata['sim'][sim_id]['xinit'][0],\n",
    "#              'temperature' :simdata['sim'][sim_id]['xinit'][1],\n",
    "#              'evm' : simdata['sim'][sim_id]['xinit'][2],\n",
    "#              'rhoc' : simdata['sim'][sim_id]['xinit'][3],\n",
    "#              'rhow' : simdata['sim'][sim_id]['xinit'][4],\n",
    "#              'flux' : simdata['sim'][sim_id]['xinit'][5],\n",
    "#              } #used just to define a model\n",
    "# f = Func(model, data_transform, init_data)\n",
    "\n",
    "# x0 = xtr_full[1000, 2:5]\n",
    "\n",
    "# check_grad(f.eval, f.eval_jacobian, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2539628-4d6d-4bd4-9ac9-557727a049a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import approx_fprime\n",
    "\n",
    "# sim_id = 0\n",
    "# init_data = {'vmJ2' : simdata['sim'][sim_id]['xinit'][0],\n",
    "#              'temperature' :simdata['sim'][sim_id]['xinit'][1],\n",
    "#              'evm' : simdata['sim'][sim_id]['xinit'][2],\n",
    "#              'rhoc' : simdata['sim'][sim_id]['xinit'][3],\n",
    "#              'rhow' : simdata['sim'][sim_id]['xinit'][4],\n",
    "#              'flux' : simdata['sim'][sim_id]['xinit'][5],\n",
    "#              } #used just to define a model\n",
    "f = ModelWrapper(model, data_transform, init_data)\n",
    "\n",
    "#x0 = xtr_full[50000, 2:5] #requires HT9 dataset \n",
    "x0 = np.array([2.32967174e-02, 1.90846970e+12, 6.66795851e+12]) #just an example point\n",
    "#x0 = 100*np.random.rand(3) #this data point is unlikely to be in the relevant region of the input space, but we can still perform evaluations as a test.\n",
    "\n",
    "J = f.eval_jacobian(x0) # based on formulas implemented above and in data_transforms.py\n",
    "\n",
    "Jfd = approx_fprime(x0, f.eval, epsilon = 1e-30) #very small epsilon are needed for accurate finite difference approximations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b51c08-db1f-461d-9270-c0d3b3e612e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.80411722e+00,  1.17431627e-13,  1.38752595e-13],\n",
       "       [ 2.80443323e+13, -5.50367257e-01, -9.22529403e-01],\n",
       "       [ 1.68246314e+14, -2.07063543e+00, -3.91520040e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7594b80-070d-42e9-a649-74c1c359e34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.80411587e+00,  1.17431617e-13,  1.38752645e-13],\n",
       "       [ 2.80443218e+13, -5.50367405e-01, -9.22529742e-01],\n",
       "       [ 1.68246211e+14, -2.07063525e+00, -3.91520167e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e299ba9a-705b-45ba-90ec-8cb8e300bb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.08092910e-02, -7.28390357e+11, -2.73717052e+12])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.eval(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6ab9b-c797-4bb2-b3e9-6dafc6197221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
