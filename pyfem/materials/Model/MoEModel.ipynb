{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a435982-f96a-4e47-a965-37bb42299020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import torch\n",
    "from model import MixtureOfExperts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "603c1337-dced-4548-921d-2bd9824bb972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixtureOfExperts(\n",
       "  (gate): SoftmaxGate(\n",
       "    (linear_gate): LinearHN(\n",
       "      (hn): MLP(\n",
       "        (sequential): Sequential(\n",
       "          (0): Linear(in_features=6, out_features=128, bias=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): SiLU()\n",
       "          (3): Dropout(p=0.5, inplace=False)\n",
       "          (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (6): SiLU()\n",
       "          (7): Dropout(p=0.5, inplace=False)\n",
       "          (8): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (9): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (10): SiLU()\n",
       "          (11): Dropout(p=0.5, inplace=False)\n",
       "          (12): Linear(in_features=128, out_features=448, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (linear): Linear(in_features=6, out_features=64, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (experts): ModuleList(\n",
       "    (0-63): 64 x LinearHN(\n",
       "      (hn): MLP(\n",
       "        (sequential): Sequential(\n",
       "          (0): Linear(in_features=6, out_features=32, bias=True)\n",
       "          (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): SiLU()\n",
       "          (3): Dropout(p=0.5, inplace=False)\n",
       "          (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (5): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (6): SiLU()\n",
       "          (7): Dropout(p=0.5, inplace=False)\n",
       "          (8): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (9): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (10): SiLU()\n",
       "          (11): Dropout(p=0.5, inplace=False)\n",
       "          (12): Linear(in_features=32, out_features=21, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (linear): Linear(in_features=6, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loading pytorch model\n",
    "\n",
    "model_name = f\"model_experiment_5_1101443/checkpoint_savetime_1101443_batchsize_16384_numexperts_64.pt\"\n",
    "device = 'cpu'\n",
    "num_experts = int( model_name.split('_')[-1][:-3] )\n",
    "num_vars = 6\n",
    "gate_features = 128\n",
    "expert_features = 32\n",
    "out_features = 3\n",
    "model = MixtureOfExperts(num_vars, gate_features, expert_features, out_features, num_experts)\n",
    "model.load_state_dict(torch.load(model_name, map_location=torch.device(device)))\n",
    "model.to(torch.double)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c57dc2cb-ba6a-404a-94ff-a16691d6480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"transform.pickle\",\"rb\") as fhandle:\n",
    "    data_transform = pickle.load(fhandle)\n",
    "\n",
    "with open(f\"init_data.pickle\",\"rb\") as fhandle:\n",
    "    init_data = pickle.load(fhandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac7e2964-b340-4338-868e-40815d7f0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "## surrogate eval and jacobian wrapper, for pointwise evaluations\n",
    "\n",
    "class ModelWrapper:\n",
    "\n",
    "    def __init__(self, model, data_transform, init_data):\n",
    "        self.data_transform = data_transform\n",
    "        self.model = model\n",
    "        self.init_data = init_data\n",
    "        \n",
    "        self.ninputs = self.data_transform['input'].length\n",
    "        self.noutputs = self.data_transform['output'].length\n",
    "\n",
    "    def eval(self, x: np.array):\n",
    "        # x is (n,)\n",
    "        x_extended = np.array([x])\n",
    "        z = torch.tensor(self.data_transform['input'].transform(x_extended), dtype=torch.double)         \n",
    "        # eval surrogates              \n",
    "        with torch.no_grad():\n",
    "            outs  = self.model(z)\n",
    "        return self.data_transform['output'].inverse_transform(outs.numpy()).reshape((-1,))\n",
    "\n",
    "    def eval_jacobian(self, x: np.array):\n",
    "        '''\n",
    "        pytorch jacobian modified from\n",
    "        https://gist.github.com/sbarratt/37356c46ad1350d4c30aefbd488a4faa\n",
    "        '''\n",
    "        # x is (n,)\n",
    "\n",
    "        x_extended = np.array([x])\n",
    "        Jin = self.data_transform['input'].forward_derivative(x_extended)\n",
    "        z = torch.tensor( self.data_transform['input'].transform(x_extended), dtype=torch.double).squeeze()\n",
    "        z = z.repeat(self.noutputs, 1)\n",
    "        z.requires_grad_(True)\n",
    "        y = self.model(z)\n",
    "        y.backward(torch.eye(self.noutputs))\n",
    "        Jmod = z.grad.data.numpy()\n",
    "        Jout = data_transform['output'].inverse_derivative( y[0].detach().numpy()[None,:] )\n",
    "        J = Jout[:,None]*(Jmod * Jin) # (3,6) jacobian for all 6 inputs\n",
    "        return J # (3,3) jacobian for just the state variables \n",
    "\n",
    "    def eval_func_wrapper(self, t, x):\n",
    "        '''\n",
    "        wrapper for scipy.integrate.solve_ivp\n",
    "        '''\n",
    "        return self.eval(x)\n",
    "\n",
    "    def eval_jacobian_wrapper(self, t, x):\n",
    "        '''\n",
    "        wrapper for scipy.integrate.solve_ivp\n",
    "        '''\n",
    "        return self.eval_jacobian(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c657b1-7dfc-4b72-a4bf-54a582b51ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi = ModelWrapper(model, data_transform, init_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da67f906-c904-4275-9122-1ab8eb11fdfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.97202342e-12, 8.20187736e+17, 7.71206023e+09])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''set1 = np.array([0.119132960099, 600.0690046472204, 0.0, 4669.9511535360325, 4406641771830.477, 1.018454806316354e-09])\n",
    "Phi.eval(set1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3d808-28ee-46e6-961a-15a8310b35c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
